{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44fbf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77297093",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c0d1336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\alexb\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "#!huggingface-cli login\n",
    "from huggingface_hub import login\n",
    "login(token=\"\", write_permission=True)" 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c0fdde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c89e6432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda\\envs\\adobe-pdf\\lib\\site-packages\\datasets\\load.py:922: FutureWarning: The repository for dutch_archaeo_ner contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at fold1/dutch_archaeo_ner.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Generating train split: 22150 examples [00:02, 8401.11 examples/s] \n",
      "Generating validation split: 5852 examples [00:00, 6805.86 examples/s]\n",
      "Generating test split: 5750 examples [00:00, 6751.86 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#fold1 = load_dataset(\"fold1/dutch_archaeo_ner.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c5fdaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 20039 examples [00:02, 8217.43 examples/s]\n",
      "Generating validation split: 5747 examples [00:00, 7569.09 examples/s]\n",
      "Generating test split: 7965 examples [00:00, 9449.09 examples/s] \n"
     ]
    }
   ],
   "source": [
    "fold1 = load_dataset(\"fold1/dutch_archaeo_ner.py\", trust_remote_code=True)\n",
    "fold2 = load_dataset(\"fold2/dutch_archaeo_ner.py\", trust_remote_code=True)\n",
    "fold3 = load_dataset(\"fold3/dutch_archaeo_ner.py\", trust_remote_code=True)\n",
    "fold4 = load_dataset(\"fold4/dutch_archaeo_ner.py\", trust_remote_code=True)\n",
    "fold5 = load_dataset(\"fold5/dutch_archaeo_ner.py\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60b18520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['OPGRAVINGEN',\n", 
       "  'OP',\n",
       "  '’',\n",
       "  'T',\n",
       "  'KLUMKE',\n",
       "  'TE',\n",
       "  'NIJMEGEN-OOSTERHOUT'],\n",
       " 'ner_tags': [0, 0, 5, 6, 6, 6, 6]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold1['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38e62821",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_folds = DatasetDict({\n",
    "    \"fold1_train\": fold1['train'],   \n",
    "    \"fold1_validation\": fold1['validation'],   \n",
    "    \"fold1_test\": fold1['test'],   \n",
    "    \"fold2_train\": fold2['train'],   \n",
    "    \"fold2_validation\": fold2['validation'],   \n",
    "    \"fold2_test\": fold2['test'],   \n",
    "    \"fold3_train\": fold3['train'],   \n",
    "    \"fold3_validation\": fold3['validation'],   \n",
    "    \"fold3_test\": fold3['test'],   \n",
    "    \"fold4_train\": fold4['train'],   \n",
    "    \"fold4_validation\": fold4['validation'],   \n",
    "    \"fold4_test\": fold4['test'],   \n",
    "    \"fold5_train\": fold5['train'],   \n",
    "    \"fold5_validation\": fold5['validation'],   \n",
    "    \"fold5_test\": fold5['test'],   \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3044edea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 23/23 [00:00<00:00, 442.42ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 307.41ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 200.20ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 23/23 [00:00<00:00, 425.56ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 176.49ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 200.01ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 20/20 [00:00<00:00, 215.06ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 9/9 [00:00<00:00, 596.68ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 162.18ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 18/18 [00:00<00:00, 187.50ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n",
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 235.27ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n",
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 9/9 [00:00<00:00, 219.51ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s]\n",
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 21/21 [00:00<00:00, 241.93ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n",
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 171.48ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 285.77ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "README.md: 100%|██████████| 5.35k/5.35k [00:00<00:00, 1.07MB/s]\n",
      "D:\\Software\\Anaconda\\envs\\adobe-pdf\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\alexb\\.cache\\huggingface\\hub\\datasets--alexbrandsen--archaeo_ner_dutch. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/alexbrandsen/archaeo_ner_dutch/commit/02f13e05204f8c737501ba320fe45c9d12ba08d2', commit_message='Upload dataset', commit_description='', oid='02f13e05204f8c737501ba320fe45c9d12ba08d2', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_folds.push_to_hub(\"alexbrandsen/archaeo_ner_dutch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1502e3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 5.68k/5.68k [00:00<00:00, 3.55MB/s]\n",
      "Downloading data: 100%|██████████| 891k/891k [00:00<00:00, 2.25MB/s]\n",
      "Downloading data: 100%|██████████| 299k/299k [00:00<00:00, 822kB/s]\n",
      "Downloading data: 100%|██████████| 304k/304k [00:00<00:00, 940kB/s]\n",
      "Downloading data: 100%|██████████| 915k/915k [00:00<00:00, 2.02MB/s]\n",
      "Downloading data: 100%|██████████| 284k/284k [00:00<00:00, 528kB/s]\n",
      "Downloading data: 100%|██████████| 299k/299k [00:00<00:00, 827kB/s]\n",
      "Downloading data: 100%|██████████| 928k/928k [00:00<00:00, 2.20MB/s]\n",
      "Downloading data: 100%|██████████| 288k/288k [00:00<00:00, 798kB/s]\n",
      "Downloading data: 100%|██████████| 284k/284k [00:00<00:00, 863kB/s]\n",
      "Downloading data: 100%|██████████| 882k/882k [00:00<00:00, 2.04MB/s]\n",
      "Downloading data: 100%|██████████| 327k/327k [00:00<00:00, 879kB/s]\n",
      "Downloading data: 100%|██████████| 284k/284k [00:00<00:00, 720kB/s]\n",
      "Downloading data: 100%|██████████| 862k/862k [00:00<00:00, 1.63MB/s]\n",
      "Downloading data: 100%|██████████| 304k/304k [00:00<00:00, 822kB/s]\n",
      "Downloading data: 100%|██████████| 327k/327k [00:00<00:00, 868kB/s]\n",
      "Generating fold1_train split: 100%|██████████| 22150/22150 [00:00<00:00, 275692.12 examples/s]\n",
      "Generating fold1_validation split: 100%|██████████| 5852/5852 [00:00<00:00, 382417.22 examples/s]\n",
      "Generating fold1_test split: 100%|██████████| 5750/5750 [00:00<00:00, 409586.09 examples/s]\n",
      "Generating fold2_train split: 100%|██████████| 22465/22465 [00:00<00:00, 640363.72 examples/s]\n",
      "Generating fold2_validation split: 100%|██████████| 5431/5431 [00:00<00:00, 362403.99 examples/s]\n",
      "Generating fold2_test split: 100%|██████████| 5865/5865 [00:00<00:00, 391053.21 examples/s]\n",
      "Generating fold3_train split: 100%|██████████| 19560/19560 [00:00<00:00, 592085.75 examples/s]\n",
      "Generating fold3_validation split: 100%|██████████| 8757/8757 [00:00<00:00, 626185.22 examples/s]\n",
      "Generating fold3_test split: 100%|██████████| 5427/5427 [00:00<00:00, 258699.91 examples/s]\n",
      "Generating fold4_train split: 100%|██████████| 17029/17029 [00:00<00:00, 486485.33 examples/s]\n",
      "Generating fold4_validation split: 100%|██████████| 7963/7963 [00:00<00:00, 318546.13 examples/s]\n",
      "Generating fold4_test split: 100%|██████████| 8755/8755 [00:00<00:00, 416518.81 examples/s]\n",
      "Generating fold5_train split: 100%|██████████| 20039/20039 [00:00<00:00, 607462.00 examples/s]\n",
      "Generating fold5_validation split: 100%|██████████| 5747/5747 [00:00<00:00, 410473.83 examples/s]\n",
      "Generating fold5_test split: 100%|██████████| 7965/7965 [00:00<00:00, 529977.02 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"alexbrandsen/archaeo_ner_dutch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651c7fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
